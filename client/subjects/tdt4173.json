{"subject": "Machine Learning and Case-Based Reasoning", "questions": [{"question": "When does the Candidate Elimination algorithm accurately classify a given instance positive or negative?", "answer": " When half the version space hypothesis classify it as postive, and the other half as negative"}, {"question": "A hypothesis $h$ is consistent with a set of training examples $D$ iff:", "answer": " $Consistent(h,D) \\equiv (\\forall \\big< x, c(x) \\big> \\in D) h(x) = c(x)$"}, {"question": "Weakness of the Naive Bayes assumption?", "answer": " It's restrictive. I many cases the attributes can be said to be dependent (e.g. thunder and rain)"}, {"question": "When do we use the EM-algorithm?", "answer": " The EM-algorithm is used when we have a distribution of $k$ different normal distributuon, and we want to find the $k$ mean-values. It searches for the $h_{MAP}$ by repeatedly re-estimating the expected values of the hidden variables $z_{ij}$ given its current hypothesis $u_1, \\dots u_k$"}, {"question": "What is an 'unstable' learning algorithm?", "answer": " Algorithms whose output classifier undergoes major changes in response to small changes in the training data. Typical algorithms are: decision-trees, ANNs and rule-learning algorithms."}, {"question": "What is the $M$-parameter in the Extra-Trees algorithm?", "answer": " $M$ is the number of trees in the ensemble."}, {"question": "What do we mean by \"bias in the estimate\" in terms of evaluating hypotheses?", "answer": " The observed accuracy of the learned hypothesis over the training examples is often a poor estimator of its accuracy in future examples. This yields an biased estimate."}, {"question": "What's the four main phases of the CBR-cycle?", "answer": " Retrieve, Reuse, Revise and Retain"}, {"question": "What is the inductive learning hypothesis?", "answer": " Any hypothesis found to approximate the target function well over a sufficiently large set of training examples will also approximate the target function well over other unobserved examples."}, {"question": "What's the assumption of the Naive Bayes Classifier?", "answer": " All attributes are independent of each other. <br> $P(a_1 , a_2, \\dots , a_n |v_j) = \\prod_{i} P(a_i|v_j)$"}, {"question": "What is a 'kernel' in SVM?", "answer": " In order to solve the problem in a higher dimension it's defined a $K(x_i, x_j) = \\theta (x_i)^{T} \\theta (x_j)$. The different kernels have different properties, and finding the right for your problem is a difficult task."}, {"question": "What is the definition of overfitting? (the 'formula')", "answer": " $error_{s}(h) < error_{s}(h^{'})$ and $error_D (h) > error_D (h^{'})$"}, {"question": "When designing a new learning program, what are the main design decisions?", "answer": " Training Experience <br> Target Function <br> Representation of the target function <br> Function approximation algorithm"}, {"question": "Give a textual description of overfitting:", "answer": " A hypothesis overfitts a training set if another hypothesis has higher training error, but less error in the entire distribution $D$."}, {"question": "What is the run time complexity of the Naive Bayes classifier (both learning and classifying)?", "answer": " Classifying = $O(|V|n)$ <br> Learning = $O(|V|n|T|)$"}, {"question": "Some post-prune techniques has been presented, explain rule post-pruning:", "answer": " This approach infers the DT from the training set (growing the tree until the training data fits as well as possible, while allowing overfitting). It then converts the tree to set of rules by creating a rule for each path from root to leaf. Then it sorts the rules by estimated accuracy and and prunes the rules whose removal does not worsen its estimated accuracy."}, {"question": "What's the M-step in the EM-algorithm?", "answer": " Replace the hypothesis $h$ by the hypothesis $h^{'}$ that maximizes the Q-function: <br> $h \\leftarrow \\underset{h^{'}}{argmax} ~Q(h^{'}|h)$"}, {"question": "What's the purpouse of the EM-algorithm?", "answer": " It is an iterative method for finding the MAP estimate of variables. Used to find/estimate the probability distributions for unobserved variables."}, {"question": "SVM are called 'large margin classifiers', why?", "answer": " The supporting planes are pushed apart until they bump into the support vectors."}, {"question": "Formula for the sample error:", "answer": " $error_s (h) \\equiv \\frac{1}{n}\\sum_{x\\in S}\\gamma(f(x), h(x))$"}, {"question": "Give two algorithms that use a-priori knowledge:", "answer": " Bayesian Network and"}, {"question": "Which of the following has an inductive bias? Rote Learner, Candidate Elimination or Find-S?", "answer": " Candidate Elimination and Find-S"}, {"question": "Two methods for avoiding overfitting in ID3?", "answer": " Stop growing when data split is not statistically significant. Secondly grow the full tree, then post prune the tree."}, {"question": "Can we learn withot inductive bias?", "answer": " Yes, but in order to learn the entire hypothesis space, you must apply as much data as there is in the whole world. Must know everything to learn everything."}, {"question": "What's a lazy learner in terms of instance-based learning and case-based reasoning?", "answer": " The learner does not generalize beyond the training data until a new query instance is observed"}, {"question": "What do we mean by \"variance in the estimate\" in terms of evaulating hypotheses?", "answer": " We need a larger test set, since the smaller test examples, the greater the expected variance."}, {"question": "Define the general-to-specific ordering of hypotheses:", "answer": " If any instance classified as positive by a hypothesis $h_1$ is also classified positive by a more general hypothesis $h_2$, we have the more-general-relationship. It's written $h_j \\geq_{g} h_k$"}, {"question": "The prior probability of $h$ is:", "answer": " $P(h)$"}, {"question": "There are two types of inductive bias, name them:", "answer": " Restriction bias, that is: a restriction in the hypothesis space. <br> Preference bias, that is: Like in ID3, we prefer small trees and high information gain close to the root."}, {"question": "What is the $K$-parameter in the Extra-Trees algorithm?", "answer": " $K$ is the number of attributes randomly selected at each node."}, {"question": "Define a weak classifier:", "answer": " Weak classifiers are classifiers which perform only slightly better than a random classifier."}, {"question": "What's Bayes' Theorem?", "answer": " $P(h|D) = \\frac{P(D|h)P(h)}{P(D)}$"}, {"question": "What's the main idea behind Occam's Razor?", "answer": " Prefer the shortest hypothesis that fits the data. Said otherwise: maximize complexity and simplicity."}, {"question": "Mathematical definition of $h_{ML}$:", "answer": " $h_{ML} \\equiv \\underset{h \\in H}{argmax}~ P(D|h)$"}, {"question": "What is the $n_{min}$ parameter in the Extra-Trees algorithm?", "answer": " $n_{min}$ is the minimum sample size for splitting a node."}, {"question": "The most general hypothesis is:", "answer": " $\\big< ?,?,?,?,?,? \\big>$"}, {"question": "Under which conditions is ML identical to MAP?", "answer": " When $P(h)$ is a uniform distribution"}, {"question": "The case-based interpeter in CREEK contains a three-step process. Elaborate about this process:", "answer": " Activation: activating relevant parts of the semantic network <br> Explain: generating and explaining derived information within the activated knowledge structure <br> Focus: focus towards and selecting a conclusion that confirms with the goal."}, {"question": "What is the formula for the Naive Bayes Classifier?", "answer": " $v_{NB} = \\underset{v_j \\in V}{argmax} ~P(v_j) \\prod_{i} P(a_j|v_j)$"}, {"question": "The formal definition of general-to-specific ordering of hypotheses is true iff:", "answer": " $(\\forall x \\in X)[(h_k (x) = 1) \\rightarrow (h_j (x) = 1)]$"}, {"question": "Some post-prune techniques has been presented, explain reduced error pruning:", "answer": " This approach consideres each node a candidate for pruning. It removes the entire subtree of a node, making the node a leaf node. Nodes are removed only if the resulting tree performs no worse than the original over the validation set. The pruning is greedy."}, {"question": "What's the Brute-Force Bayes Concept Learning? Pseudocode and description:", "answer": " It's a straightforward concept learning algorithm that outputs the $h_{MAP}$ by iterating each $h \\in H$ and calculate the posterior probability by Bayes' Theorem. Finally it outputs the one with the highes probability: <br> $h_{MAP} = \\underset{h \\in H}{argmax} P(h|D)$"}, {"question": "The main idea of the FIND-S algorithm is:", "answer": " Exploit the more-general-relationship to find the maximum specific hypothesis. Start with the most specific, and iterate every positive training example. For each attribute that is satisfied, do nothing. Else replace the attribute with the next more general constraint."}, {"question": "When is a class $C$ PAC-learnable by a learner $L$ with a hypothesis space $h$?", "answer": " When <br> $c\\in C$ <br> distributuons $D$ over $X$ <br> $\\epsilon$ such that $0 < \\epsilon < 1/2$, and <br> $\\delta$ such that $0 < \\delta < 1/2$"}, {"question": "Give an example of a well-posed learning problem? (The answer will be an indication on how it should look like)", "answer": " Task T: playing checkers <br> Performance measure P: percent of games won against opponents <br> Training experience E: playing practice games against itself"}, {"question": "When does the Candidate Elimination algorithm classify all instances as either positive or negative?", "answer": " When S and G converge to a single, identical, hypothesis."}, {"question": "Give two algorithms that use a-posteriori knowledge:", "answer": " SVM and Decision Tree Learning"}, {"question": "What is 'bagging'?", "answer": " Bagging is a collection of weak classifiers where each one of them gets data set of $m$ training examples drawn randomly with replacement from the original training set. The final classification is done by a majority vote of all the classifiers. The weak classifier should be unstable (small changes in training set, leads to large variations in classification)."}, {"question": "What's explanation-based learning?", "answer": " It's an analytical learning algorithm. It starts with an empty hypothesis and iterates each positive training example not covered by $h$. Each iterations goes through the steps: Explan, Analyze and Refine."}, {"question": "The most specific hypothesis is:", "answer": " $\\big< \\emptyset,\\emptyset,\\emptyset,\\emptyset,\\emptyset,\\emptyset \\big>$"}, {"question": "Mathematical definition of $h_{MAP}$:", "answer": " $h_{MAP} = \\underset{h \\in H}{argmax}~ P(D|h)P(h)$"}, {"question": "The probability of observing $D$ in a world where $h$ holds is:", "answer": " $P(D|h)$"}, {"question": "Give a textual definition of the inductive bias:", "answer": " The inductive bias is the set of assumptions made by a learner to be able to generalize from training examples"}, {"question": "The joint probability distribution over all variables in a Bayesian Network are:", "answer": " $P(y_1, \\dots ,y_n) = \\prod_{i=1}^{n}P(y_i|parents(y_i))$"}, {"question": "What is cross-validation?", "answer": " Cross-validation is to leave out a piece of the training set, and use it to check if their classified correct after training."}, {"question": "Give a brief overview of analytical learning:", "answer": " Analytical learning adds a body of domain knowledge when it learns. This makes it contain a domain theory for explaining the examples. This is in addition to the regular instances, hypotheses, target concept and training examples. The task then is to determine if a hypothesis is consistent with the training examples and the domain theory."}, {"question": "Definition of version space ($VS_{H,D}$):", "answer": " $VS_{HD} \\equiv \\big\\{ h \\in H | Consistent(h,D) \\big\\}$"}, {"question": "Give the formal definition of inductive bias:", "answer": " The inductive bias of $L$ is any minimal set of assertions $B$ such that for any target concept $c$ and corresponding training examples $D_c$: <br> $(\\forall x_i \\in X)[(B \\land D_c \\land X_i ) \\vdash L(x_i , D_c)]$"}, {"question": "Define a well-posed learing problem:", "answer": " A computer is said to learn from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, as measured by $P$, improves with experience $E$."}, {"question": "What's the E-step in the EM-algorithm?", "answer": " Calculate $Q(h^{'}|h)$ using the current hypothesis $h$ and the observed data $X$ to estimate the probability distribution over Y. <br> $Q(h^{'}|h) \\leftarrow E[ln ~P(Y|h^{'})|h, X]$"}, {"question": "Formula for the true error:", "answer": " $error_D (h) \\equiv \\underset{x\\in D}{Pr}[f(x) \\neq h(x)]$"}], "code": "TDT4173"}