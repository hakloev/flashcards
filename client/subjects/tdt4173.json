{"code": "TDT4173", "subject": "Machine Learning and Case-Based Reasoning", "questions": [{"question": "Definition of version space ($VS_{H,D}$):", "answer": " $VS_{HD} \\equiv \\big\\{ h \\in H | Consistent(h,D) \\big\\}$"}, {"question": "What's the E-step in the EM-algorithm?", "answer": " Calculate $Q(h^{'}|h)$ using the current hypothesis $h$ and the observed data $X$ to estimate the probability distribution over Y. <br> $Q(h^{'}|h) \\leftarrow E[ln ~P(Y|h^{'})|h, X]$"}, {"question": "Mathematical definition of $h_{MAP}$:", "answer": " $h_{MAP} = \\underset{h \\in H}{argmax}~ P(D|h)P(h)$"}, {"question": "The most specific hypothesis is:", "answer": " $\\big< \\emptyset,\\emptyset,\\emptyset,\\emptyset,\\emptyset,\\emptyset \\big>$"}, {"question": "What is the definition of overfitting? (the 'formula')", "answer": " $error_{s}(h) < error_{s}(h^{'})$ and $error_D (h) > error_D (h^{'})$"}, {"question": "What is the inductive learning hypothesis?", "answer": " Any hypothesis found to approximate the target function well over a sufficiently large set of training examples will also approximate the target function well over other unobserved examples."}, {"question": "Two methods for avoiding overfitting in ID3?", "answer": " Stop growing when data split is not statistically significant. Secondly grow the full tree, then post prune the tree."}, {"question": "Can we learn withot inductive bias?", "answer": " Yes, but in order to learn the entire hypothesis space, you must apply as much data as there is in the whole world. Must know everything to learn everything."}, {"question": "Give two algorithms that use a-priori knowledge:", "answer": " Bayesian Network and"}, {"question": "Give two algorithms that use a-posteriori knowledge:", "answer": " SVM and Decision Tree Learning"}, {"question": "What is 'bagging'?", "answer": " Bagging is a collection of weak classifiers where each one of them gets data set of $m$ training examples drawn randomly with replacement from the original training set. The final classification is done by a majority vote of all the classifiers. The weak classifier should be unstable (small changes in training set, leads to large variations in classification)."}, {"question": "What's the assumption of the Naive Bayes Classifier?", "answer": " All attributes are independent of each other. <br> $P(a_1 , a_2, \\dots , a_n |v_j) = \\prod_{i} P(a_i|v_j)$"}, {"question": "What is cross-validation?", "answer": " Cross-validation is to leave out a piece of the training set, and use it to check if their classified correct after training."}, {"question": "The most general hypothesis is:", "answer": " \\big< ?,?,?,?,?,? \\big>$"}, {"question": "Formula for the sample error:", "answer": " $error_s (h) \\equiv \\frac{1}{n}\\sum_{x\\in S}\\gamma(f(x), h(x))$"}, {"question": "Which of the following has an inductive bias? Rote Learner, Candidate Elimination or Find-S?", "answer": " Candidate Elimination and Find-S"}, {"question": "SVM are called 'large margin classifiers', why?", "answer": " The supporting planes are pushed apart until they bump into the support vectors."}, {"question": "The main idea of the FIND-S algorithm is:", "answer": " Exploit the more-general-relationship to find the maximum specific hypothesis. Start with the most specific, and iterate every positive training example. For each attribute that is satisfied, do nothing. Else replace the attribute with the next more general constraint."}, {"question": "Define a well-posed learing problem:", "answer": " A computer is said to learn from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, as measured by $P$, improves with experience $E$."}, {"question": "When do we use the EM-algorithm?", "answer": " The EM-algorithm is used when we have a distribution of $k$ different normal distributuon, and we want to find the $k$ mean-values. It searches for the $h_{MAP}$ by repeatedly re-estimating the expected values of the hidden variables $z_{ij}$ given its current hypothesis $u_1, \\dots u_k$"}, {"question": "What's the four main phases of the CBR-cycle?", "answer": " Retrieve, Reuse, Revise and Retain"}, {"question": "A hypothesis $h$ is consistent with a set of training examples $D$ iff:", "answer": " $Consistent(h,D) \\equiv (\\forall \\big< x, c(x) \\big> \\in D) h(x) = c(x)$"}, {"question": "Formula for the trye error:", "answer": " $error_D (h) \\equiv \\underset{x\\in D}{Pr}[f(x) \\neq h(x)]$"}, {"question": "There are two types of inductive bias, name them:", "answer": " Restriction bias, that is: a restriction in the hypothesis space. <br> Preference bias, that is: Like in ID3, we prefer small trees and high information gain close to the root."}, {"question": "Weakness of the Naive Bayes assumption?", "answer": " It's restrictive. I many cases the attributes can be said to be dependent (e.g. thunder and rain)"}, {"question": "What is the formula for the Naive Bayes Classifier?", "answer": " $v_{NB} = \\underset{v_j \\in V}{argmax} ~P(v_j) \\prod_{i} P(a_j|v_j)$"}, {"question": "Give a textual description of overfitting:", "answer": " A hypothesis overfitts a training set if another hypothesis has higher training error, but less error in the entire distribution $D$."}, {"question": "What's the M-step in the EM-algorithm?", "answer": " Replace the hypothesis $h$ by the hypothesis $h^{'}$ that maximizes the Q-function: <br> $h \\leftarrow \\underset{h^{'}}{argmax} ~Q(h^{'}|h)$"}, {"question": "Mathematical definition of $h_{ML}$:", "answer": " $h_{ML} \\equiv \\underset{h \\in H}{argmax}~ P(D|h)$"}, {"question": "What is a 'kernel' in SVM?", "answer": " In order to solve the problem in a higher dimension it's defined a $K(x_i, x_j) = \\theta (x_i)^{T} \\theta (x_j)$. The different kernels have different properties, and finding the right for your problem is a difficult task."}, {"question": "Define the general-to-specific ordering of hypotheses:", "answer": " If any instance classified as positive by a hypothesis $h_1$ is also classified positive by a more general hypothesis $h_2$, we have the more-general-relationship. It's written $h_j \\geq_{g} h_k$"}, {"question": "Define a weak classifier:", "answer": " Weak classifiers are classifiers which perform only slightly better than a random classifier."}]}