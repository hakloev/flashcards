Machine Learning and Case-Based Reasoning
TDT4173
What is the formula for the Naive Bayes Classifier:= $v_{NB} = \underset{v_j \in V}{argmax} ~P(v_j) \prod_{i} P(a_j|v_j)$
Define a well-posed learing problem:= A computer is said to learn from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, as measured by $P$, improves with experience $E$.
What is the inductive learning hypothesis:= Any hypothesis found to approximate the target function well over a sufficiently large set of training examples will also approximate the target function well over other unobserved examples.
A hypothesis $h$ is consistent with a set of training examples $D$ iff:= $Consistent(h,D) \equiv (\forall \big< x, c(x) \big> \in D) h(x) = c(x)$
Definition of version space ($VS_{H,D}$):= $VS_{HD} \equiv \big\{ h \in H | Consistent(h,D) \big\}$
Which of the following has an inductive bias? Rote Learner, Candidate Elimination or Find-S:= Candidate Elimination and Find-S
What's the E-step in the EM-algorithm?:= Calculate $Q(h^{'}|h)$ using the current hypothesis $h$ and the observed data $X$ to estimate the probability distribution over Y. <br> $Q(h^{'}|h) \leftarrow E[ln ~P(Y|h^{'})|h, X]$
What's the M-step in the EM-algorithm?:= Replace the hypothesis $h$ by the hypothesis $h^{'}$ that maximizes the Q-function: <br> $h \leftarrow \underset{h^{'}}{argmax} ~Q(h^{'}|h)$
What's the four main phases of the CBR-cycle?:= Retrieve, Reuse, Revise and Retain
Define a weak classifier:= Weak classifiers are classifiers which perform only slightly better than a random classifier.
